boost
=====

Extensions/modifications of stock Boost components (mostly based on C++11
standard).

boost::mpl::x11
---------------

IMPORTANT: _A throughly cleaned up and fully variadic version of this MPL
implementation is now available as part of
https://github.com/oakad/ucpf/tree/master/yesod/yesod/mpl[ucpf::yesod::mpl]
repository._

Original boost::mpl library was a major milestone in the evolution of C\++
programing language. But apart of being an example of advanced C++ thinking
it also serves as example of hardcore preprocessor programming. Clearly,
the goals of mpl could not be achieved in any other way back in early years
of present century (mpl is more than 10 years old already, being developed
since year 2000). Unfortunately, extensive use of preprocessor obstructs
easy analysis and inspection of non-trivial library behavior.

boost::mpl::x11 is a cosmetic rewrite of mpl library, featuring the
following traits:

1. It stays as close as possible to the original mpl implementation wise.
2. All preprocessor and compiler dependent code is stripped outright.
3. Variadic templates are used wherever possible without departing too much
from p.1. This means that variadic templates are used for everything apart from
mpl::bind and mpl::lambda classes (those are implemented in semy-variadic
fashion). Larry Evans had proposed an alternative, fully variadic implementation
in his prior work, but I decided not to pull it in for a time being.
4. Some features of Larry Evans' work on boost.sandbox version of the mpl
are taken advantage of (package<> sequence and argument sequence unpacking;
more may follow).

boost::mpl::x11 is tested to work with recent enough versions of g++ and
clang++ compilers (this, basically, exhausts the list of sane, popular
compilers; MSVC compiler is not worth bothering with in its present state).

All unit tests present in the original implementation of mpl are ported over to
mpl::x11 and found working.

There's one important compatibility quirk between mpl::x11 and original mpl:
I decided not to introduce shorthand placeholders for lambda args, thus
instead of "_", "_1", "_2" and other placeholders like this, one is expected
to use a more verbose "arg\<-1>", "arg<0>", "arg<1>", etc. identifiers (
"_1" corresponds to "arg<0>" in mpl::x11, as I like counting things from zero).
It seems that in most practical programs shorthand placeholder names are
less convenient than directly exposed placeholder template, because there are
too many incompatible definitions of those in various namespaces (std
placeholders, boost placeholders and whatever other placeholders defined by
arbitrary libraries).

boost::spirit::repository
-------------------------

Few alternative parsers for use with Spirit v2 (in c++11 mode) are available
hereby.

The most important is an alternative, fully compile-time parametrizable
numeric_parser<> and its type specialized instances (uint_, int_, double_,
etc.). Unlike the original implementation, this parser supports different
charsets and numeric systems (thus, it can be used for anything numeric -
binary extraction to complex floating point number formats).

Several "static" (that is, compile-time configurable) variaties of standard
Spirit v2 parsers are provided for the sake of the above (static_char<>,
static_char_range<>, static_string<>, static_variant<> and static_symbols<>).
These parsers rely on type to value conversion algorithms provided by the
mpl::x11 library described above.

Additionally, a precise decimal string to floating point conversion algorithm
is bundled with numeric_parser<> and enabled by the default policy of float_,
double_ and long_double parsers (there's an impresise conversion policy
provided as well, matching the speed of stock Spirit v2 parser, which many
people value more than precision). Unfortunately, the bundled conversion
algorithm is rather slow (around 6 - 10 times slower that glibc's strtod
function on a modern Intel CPU). On the bright side, it is implemented purely
in terms of integer arithmetic and follows a rather original approach. Whether
it can be further optimized remains to be seen.
